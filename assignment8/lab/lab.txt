bin/zookeper-server-start.sh config/zookerper.properties at 4:20p
****LOCAL RUN ******

1 download kafka files, don't have to install them. it's bin (see shell scripts)
directory called kafka_2.11-2.2.1

2 start zookeper 
3 verify zookeepr is running - nc -vz localhost 2181 is zookeeper port
4 start kafka
bin/kafaka-server-start.sh config/server.properties 7:04p
^^is one-node cluster
log activity in oboth panes

kafka runs in 9092
nv -vc localhost 9092

'kafka ships with zookepr, it was in same kafka_2.11-2.2.1/bin/zookeepr... directory
"always stop KAFKA first THEN ZOOKEEPER"

ps -eaf grep | java
sudo kill -9 25073

^^ kafka is now stopped.

5 START KAFKA CLUSTER

****SWITCH TO DOCKER******

6 11:53
.yaml
ports: - "2181:2181" don't realy need because we're executing things inside of the container on kafka, don't need to expose it
'environment variables that container exposes'
`HOSTNAME_COMMAND
PORTS: - 9092 "makes it run on 9092, but does not expose it" "don't try expose it 9092:9092 because all nodes will be listening on 9092"

'one more containre to run the python example...'
python-example: depends_on: -fafka -zookeeper
'volumes: - "./python:/python" makes my machine's code available to the d containers....'

7 start docker...
# single-node kafka cluster
docker-compose -f kafka-docker-compose.yaml up -d
docker ps -a
(see 1 zookeepr, 1 kafka node, 1 python container)

'3 node cluster using teh scale option in docker-compose'
docker-compose -f kafka-docker-compose.yaml up -d --scale kafka=3
*WOOOAHH* so `--scale kafka=3` makes 3 of them
docker ps -a
(see 3 kafkas running)

8 18:29 connect to a running Kafka container
docker exec -it <NAME of container> bash
"it didnt matter which node we exec'd (connected) to"

9 let's try create a topic
kafka-topics.sh





20:22
bash-4.4# cd /opt/kafka/bin
connect-distributed.sh               kafka-consumer-perf-test.sh          kafka-reassign-partitions.sh         kafka-verifiable-producer.sh
connect-standalone.sh                kafka-delegation-tokens.sh           kafka-replica-verification.sh        trogdor.sh
kafka-acls.sh                        kafka-delete-records.sh              kafka-run-class.sh                   windows
kafka-broker-api-versions.sh         kafka-dump-log.sh                    kafka-server-start.sh                zookeeper-security-migration.sh
kafka-configs.sh                     kafka-log-dirs.sh                    kafka-server-stop.sh                 zookeeper-server-start.sh
kafka-console-consumer.sh            kafka-mirror-maker.sh                kafka-streams-application-reset.sh   zookeeper-server-stop.sh
kafka-console-producer.sh            kafka-preferred-replica-election.sh  kafka-topics.sh                      zookeeper-shell.sh
kafka-consumer-groups.sh             kafka-producer-perf-test.sh          kafka-verifiable-consumer.sh

22:26
--describe <topic name optional>

"The Producer specifies the ackwnoedlgement e.g. 'at least from 2 machines'"



kafka-console-consumer.sh --broker-list localhost:9092 --topic will_topic --property "parse.key=true" --property "key.separator=:"
 ?

 kafka-console-consumer.sh --bottstrap-server localhost:9092 --topic will_topic




"consumer and producers don't have to be on same machine as Kafka Server/Nodes/CLuser, as long as have binaries and port of the Cluster you can point to that"

kafka-console-producer.sh \
  --broker-list localhost:9092 \
  --topic will_topic \
  --property "parse.key=true" \
  --property "key.separator=:"



*"These kafka-console* shell scripts are just for out-of-the-box"*


# does not jus talk to 1 machine, talks to all [represented]
producer = KafkaProducer(bootstrap_servers='kafka:9092')








*HOW TO STOP ALL IN OPERATION*
docker-compose -f kafka-docker-compose.yaml down -d
11:01a put the consumer producer py's in /python so .yaml's VOLUMEs will find them, put to container

*HOW TO START AGAIN*
docker-compose -f kafka-docker-compose.yaml up -d --scale kafka=3

*DON'T FORGET KAFKA-TOPIC*
kafka-topics.sh --create --zookeeper zookeeper:2181 --replication-factor 2 --partitions 5 --topic test_topic

*GET INTO PYTHON IMAGE CONTAINER - producer*
 $ docker exec -it assignment8_python-example_1 /bin/sh
python /python/python-producer.py

*GET INTO PYTHON CONTAINER - CONSUMER*
 $ docker exec -it assignment8_python-example_1 python ./python/python-consumer.py


47:minute